{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 / 6\n"
     ]
    }
   ],
   "source": [
    "import requests,re\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "def getURL(pageNum):\n",
    "    url = 'https://careers.huntington.com/en-US/search?pagenumber='\n",
    "    urls = []\n",
    "    for i in range(pageNum):\n",
    "        urls.append(url + str(i+1))\n",
    "    return urls\n",
    "\n",
    "def getHTMLText(url):\n",
    "    try:\n",
    "        kv = {'user-agent': 'Mozilla/5.0'}\n",
    "        r = requests.get(url, headers=kv)\n",
    "        r.raise_for_status()\n",
    "        r.encoding = r.apparent_encoding\n",
    "        return r.text\n",
    "    except:\n",
    "        print('404 error!')\n",
    "        return(' ')\n",
    "\n",
    "def fillPositionList(html):\n",
    "    time.sleep(2)\n",
    "    pattern = re.compile('\"url\": \"(.*?)\"')\n",
    "    p = re.findall(pattern, html)\n",
    "    if p:\n",
    "        p_de = sorted(set(p),key=p.index)\n",
    "        return p\n",
    "    return 'N'\n",
    "\n",
    "def printCsv(sinfo):\n",
    "    df = pd.DataFrame(sinfo)\n",
    "    df.to_csv('position.csv', sep=',', header=True, index=True) # set output path\n",
    "    #print(df)\n",
    "    \n",
    "def main():\n",
    "    sinfo = []\n",
    "    urls = getURL(6) # set the number of page you want\n",
    "    i = 1\n",
    "    for url in urls:\n",
    "        html = getHTMLText(url)\n",
    "        sinfo.extend(fillPositionList(html))\n",
    "        if i % 5 == 0:\n",
    "            print(\"%d / %d\" %(i,len(urls)))\n",
    "        i += 1\n",
    "    printCsv(sinfo)\n",
    "    \n",
    "    \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pd = pd.read_csv(\"position.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = pd.DataFrame(url_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "result =url_df['0'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "type_ = []\n",
    "date = []\n",
    "location = []\n",
    "experience = []\n",
    "job_description = []\n",
    "for url in result:\n",
    "    response = get(url)\n",
    "    # print(response)\n",
    "    soup = bs(response.content,'lxml')\n",
    "    a = soup.find(\"span\", class_ = \"jdp-title-job-title\").text \n",
    "    b = soup.find(\"div\", class_ = \"job-date-posted\").text[14:-1]\n",
    "    c = soup.find(\"span\", class_ = \"jobLocation\").text\n",
    "    d = soup.find(\"div\", class_ = \"secondary-text-color\").text\n",
    "    e = soup.find(\"li\", class_ = \"job-experience\")\n",
    "    f = e.find(\"div\", class_=\"secondary-text-color\").text\n",
    "    g = soup.find(\"div\", class_=\"jdp-job-description-card content-card\").text\n",
    "    title.append(a)\n",
    "    type_.append(d)\n",
    "    date.append(b)\n",
    "    location.append(c)\n",
    "    experience.append(f)\n",
    "    job_description.append(g)\n",
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.DataFrame({\"Url\":result,\n",
    "                        \"Job Title\":title,\n",
    "                        \"Post Date\":date,\n",
    "                        \"Job Type\": type_,\n",
    "                        \"Location\":location,\n",
    "                        \"Experience\":experience, \n",
    "                        \"Job_Desciption\":job_description})\n",
    "test_df.to_csv('result.csv', sep=',', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
